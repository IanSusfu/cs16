{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer, Trainer, TrainingArguments, EarlyStoppingCallback, set_seed\n",
    "from sklearn.metrics import classification_report\n",
    "import datasets\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Song\\AppData\\Local\\Temp\\ipykernel_23556\\1786446166.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Text'] = df['Text'].apply(preprocess)\n",
      "C:\\Users\\Song\\AppData\\Local\\Temp\\ipykernel_23556\\1786446166.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Sentiment'] = df['Sentiment'].apply(adjust_ori_sentiment)\n"
     ]
    },
    {
     "data": {
      "text/plain": "    Twitter ID        Topic Sentiment  \\\n0         3364     Facebook   Neutral   \n1          352       Amazon   Neutral   \n2         8312    Microsoft  Negative   \n3         4371        CS-GO  Negative   \n4         4433       Google   Neutral   \n..         ...          ...       ...   \n95        9456    Overwatch  Negative   \n96       11687      Verizon  Negative   \n97        1589  Battlefield  Negative   \n98        3526     Facebook   Neutral   \n99        8174    Microsoft  Positive   \n\n                                                 Text  \n0   I mentioned on Facebook that I was struggling ...  \n1   BBC News - Amazon boss Jeff Bezos rejects clai...  \n2   @user Why do I pay for WORD when it functions ...  \n3   CSGO matchmaking is so full of closet hacking,...  \n4   Now the President is slapping Americans in the...  \n..                                                ...  \n95  @user so when i try to buy overwatch with a cr...  \n96  @user Can you waive some data overage charges?...  \n97  No one buy battlefield 3 on steam! It doesnâ€™t ...  \n98  Our #HISAPerth #OBIawards ceremony is taking p...  \n99  #Indigo Urgent Care looks to Microsoft Teams a...  \n\n[100 rows x 4 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Twitter ID</th>\n      <th>Topic</th>\n      <th>Sentiment</th>\n      <th>Text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>3364</td>\n      <td>Facebook</td>\n      <td>Neutral</td>\n      <td>I mentioned on Facebook that I was struggling ...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>352</td>\n      <td>Amazon</td>\n      <td>Neutral</td>\n      <td>BBC News - Amazon boss Jeff Bezos rejects clai...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>8312</td>\n      <td>Microsoft</td>\n      <td>Negative</td>\n      <td>@user Why do I pay for WORD when it functions ...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4371</td>\n      <td>CS-GO</td>\n      <td>Negative</td>\n      <td>CSGO matchmaking is so full of closet hacking,...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4433</td>\n      <td>Google</td>\n      <td>Neutral</td>\n      <td>Now the President is slapping Americans in the...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>95</th>\n      <td>9456</td>\n      <td>Overwatch</td>\n      <td>Negative</td>\n      <td>@user so when i try to buy overwatch with a cr...</td>\n    </tr>\n    <tr>\n      <th>96</th>\n      <td>11687</td>\n      <td>Verizon</td>\n      <td>Negative</td>\n      <td>@user Can you waive some data overage charges?...</td>\n    </tr>\n    <tr>\n      <th>97</th>\n      <td>1589</td>\n      <td>Battlefield</td>\n      <td>Negative</td>\n      <td>No one buy battlefield 3 on steam! It doesnâ€™t ...</td>\n    </tr>\n    <tr>\n      <th>98</th>\n      <td>3526</td>\n      <td>Facebook</td>\n      <td>Neutral</td>\n      <td>Our #HISAPerth #OBIawards ceremony is taking p...</td>\n    </tr>\n    <tr>\n      <th>99</th>\n      <td>8174</td>\n      <td>Microsoft</td>\n      <td>Positive</td>\n      <td>#Indigo Urgent Care looks to Microsoft Teams a...</td>\n    </tr>\n  </tbody>\n</table>\n<p>100 rows Ã— 4 columns</p>\n</div>"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load data\n",
    "df_orig = pd.read_csv('twitter_validation.csv', names=[\"Twitter ID\",\"Topic\",\"Sentiment\",\"Text\"])\n",
    "df = df_orig.iloc[0:100]\n",
    "\n",
    "# Preprocessing (delete username and url)\n",
    "def preprocess(text):\n",
    "    temp = []\n",
    "\n",
    "    for t in text.split(\" \"): # split a sentence into words by spaces \" \".\n",
    "        t = '@user' if t.startswith('@') and len(t) > 1 else t\n",
    "        t = 'http' if t.startswith('http') else t\n",
    "        temp.append(t)\n",
    "    return \" \".join(temp)\n",
    "\n",
    "# Change Irrelevant label into Neutral as mentioned in the data set description.\n",
    "def adjust_ori_sentiment(sentiment):\n",
    "    if sentiment == \"Irrelevant\":\n",
    "        temp_str = \"Neutral\"\n",
    "        return temp_str\n",
    "    else:\n",
    "        return sentiment\n",
    "\n",
    "df['Text'] = df['Text'].apply(preprocess)\n",
    "df['Sentiment'] = df['Sentiment'].apply(adjust_ori_sentiment)\n",
    "df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "LR = 2e-5\n",
    "EPOCHS = 30\n",
    "BATCH_SIZE = 64\n",
    "MODEL = \"cardiffnlp/twitter-roberta-base-2021-124m\" # use this to finetune the language model\n",
    "#MODEL = \"cardiffnlp/twitter-roberta-base-sentiment-latest\" # use this to finetune the sentiment classifier\n",
    "MAX_TRAINING_EXAMPLES = 7500 # set this to -1 if you want to use the whole training set"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# set transformers seed\n",
    "seed = 223\n",
    "set_seed(seed)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',                   # output directory\n",
    "    num_train_epochs=EPOCHS,                  # total number of training epochs\n",
    "    per_device_train_batch_size=BATCH_SIZE,   # batch size per device during training\n",
    "    per_device_eval_batch_size=BATCH_SIZE,    # batch size for evaluation\n",
    "    warmup_steps=100,                         # number of warmup steps for learning rate scheduler\n",
    "    weight_decay=0.01,                        # strength of weight decay\n",
    "    logging_dir='./logs',                     # directory for storing logs\n",
    "    logging_steps=160,                        # when to print log\n",
    "    evaluation_strategy='steps',              # evaluate every n number of steps.\n",
    "    eval_steps=160,                           # how often to evaluate. If not set defaults to number of logging_steps\n",
    "    load_best_model_at_end=True,              # to load or not the best model at the end\n",
    "    save_steps=160,                           # create a checkpoint every time we evaluate,\n",
    "    seed=seed                                 # seed for consistent results\n",
    "\n",
    ")\n",
    "\n",
    "\n",
    "num_labels = len(set(train_dataset['labels'])) if 'labels' in train_dataset.features.keys() else len(set(train_dataset['label']))\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(MODEL, num_labels=num_labels)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,                               # the instantiated ðŸ¤— Transformers model to be trained\n",
    "    tokenizer=tokenizer,                       # tokenizer to be used to pad the inputs\n",
    "    args=training_args,                        # training arguments, defined above\n",
    "    train_dataset=train_dataset,               # training dataset\n",
    "    eval_dataset=val_dataset,                  # evaluation dataset\n",
    "    callbacks = [EarlyStoppingCallback(3, 0.001)], # early stopping which stops the training after 3 evaluation calls with no improvement of performance of at least 0.001\n",
    ")\n",
    "\n",
    "trainer.train()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "trainer.save_model(\"./results/best_model\") # save best model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# for every prediction the model ouptuts logits where largest value indicates the predicted class\n",
    "test_preds_raw, test_labels , _ = trainer.predict(test_dataset)\n",
    "test_preds = np.argmax(test_preds_raw, axis=-1)\n",
    "print(classification_report(test_labels, test_preds, digits=3))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from scipy.special import softmax\n",
    "\n",
    "scores = softmax(test_preds_raw, axis=1)\n",
    "scores"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def get_predictions(tweets):\n",
    "    \"\"\" wrapper function to predict sentiment of tweets\"\"\"\n",
    "    with torch.no_grad():\n",
    "        encoded_input = tokenizer(\n",
    "            tweets, padding=True, truncation=True, return_tensors='pt'\n",
    "        )\n",
    "\n",
    "        # set model on evaluation mode to deactivate Dropout\n",
    "        trainer.model.eval()\n",
    "        # pass encoded text to model\n",
    "        output = trainer.model(**{k: v.to('cuda') for k, v in encoded_input.items()})\n",
    "        # get logits and move them to cpu to get the predictions\n",
    "        output = output.logits.detach().cpu().numpy()\n",
    "        predictions = np.argmax(output, axis=1)\n",
    "\n",
    "    return predictions\n",
    "\n",
    "tweets = [\"RT @UKLabour: Britain is facing the biggest rail strike in a generation but @GrantShapps hasnâ€™t spent a single second in talks to avert itâ€¦\",\n",
    "          \"Good news in todayâ€™s jobs stats: the number of employees on payrolls increased again in March.\",\n",
    "          \"I'm #live in Gladstone with my Labor team: https://t.co/chWrHtumLc\"]\n",
    "\n",
    "# get predictions\n",
    "predictions = get_predictions(tweets)\n",
    "print(predictions)\n",
    "\n",
    "# map predictions to negative/neutral/positive\n",
    "sentiment_mapping = {\n",
    "    0: 'negative',\n",
    "    1: 'neutral',\n",
    "    2: 'positive'\n",
    "}\n",
    "\n",
    "predictions = [sentiment_mapping[x] for x in predictions]\n",
    "print(predictions)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# read data into a dataframe and only keep the tweet_id (id), text,  author username, and date of tweet (created_at)\n",
    "df = pd.read_json('workshop_tweets.json', lines=True)\n",
    "df['username'] = df['author'].apply(lambda x: x['username'])\n",
    "df = df[['id', 'text', 'username', 'created_at']]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# convert pandas to huggingface Dataset & tokenize\n",
    "df = datasets.Dataset.from_pandas(df)\n",
    "df = df.map(lambda e: tokenizer(e['text'], truncation=True), batched=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# make predicitons\n",
    "output = trainer.predict(df)\n",
    "predictions = np.argmax(output.predictions, axis=1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# recast to pandas for easier visualizations\n",
    "df = df.to_pandas()\n",
    "df['sentiment'] = predictions"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# consider only UK\n",
    "df_uk = df[df['username'].isin(['BorisJohnson', 'Keir_Starmer'])]\n",
    "\n",
    "plot_uk = df_uk.groupby('sentiment')['username'].value_counts()\n",
    "for idx in plot_uk.index:\n",
    "    user_count = len(df_uk[df_uk['username'] == idx[1]])\n",
    "    plot_uk.loc[idx] = (plot_uk.loc[idx]/user_count) * 100\n",
    "\n",
    "ax = plot_uk.unstack().plot(figsize=(12,8), kind='bar',  xlabel='', legend=True, ylabel='Tweets %',  width=0.4)\n",
    "ax.set_xticklabels(['Negative', 'Neutral', 'Positive'],rotation=0)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# consider only Australia\n",
    "df_aus = df[df['username'].isin(['AlboMP', 'ScottMorrisonMP'])]\n",
    "\n",
    "plot_aus = df_aus.groupby('sentiment')['username'].value_counts()\n",
    "for idx in plot_aus.index:\n",
    "    user_count = len(df_aus[df_aus['username'] == idx[1]])\n",
    "    plot_aus.loc[idx] = (plot_aus.loc[idx]/user_count) * 100\n",
    "\n",
    "ax = plot_aus.unstack().plot(figsize=(12,8), kind='bar',  xlabel='', legend=True, ylabel='Tweets %',  width=0.4)\n",
    "ax.set_xticklabels(['Negative', 'Neutral', 'Positive'],rotation=0)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_aus['month'] = df_aus['created_at'].dt.strftime('%m')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Consider only negative and positive sentiments\n",
    "to_plot = (df_aus.groupby(['month','username'])['sentiment'].value_counts(normalize=True)*100).unstack().unstack().fillna(0)\n",
    "to_plot[[(0, 'AlboMP'), (0, 'ScottMorrisonMP'), (2, 'AlboMP'), (2, 'ScottMorrisonMP')]].plot(figsize=(19,12),\n",
    "                                                                                             color = ['red', 'red', 'blue', 'blue'],\n",
    "                                                                                             style=['-','--','-','--'],\n",
    "                                                                                             ylabel='Tweets %')\n",
    "\n",
    "plt.legend(title='',labels=['AlboMP: negative', 'ScottMorrisonMP: negative', 'AlboMP: positive','ScottMorrisonMP: positive'])"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
