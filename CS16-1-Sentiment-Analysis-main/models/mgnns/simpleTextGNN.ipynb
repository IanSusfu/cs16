{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def load_data(file_path):\n",
    "    X_data = []\n",
    "    Y_data = []\n",
    "    with open(file_path, 'r') as f:\n",
    "        for line in f:\n",
    "            example = json.loads(line.strip())\n",
    "            X_data.append(example['text'])\n",
    "            Y_data.append(example['label'])\n",
    "    return X_data, Y_data\n",
    "\n",
    "X_train, Y_train = load_data('./train_all_anno.json')\n",
    "X_test, Y_test = load_data('./test_all_anno.json')\n",
    "X_val, Y_val = load_data('./val_all_anno.json')\n",
    "\n",
    "X_train = [x.lower() for x in X_train]\n",
    "X_test = [x.lower() for x in X_test]\n",
    "X_val = [x.lower() for x in X_val]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import numpy as np\n",
    "\n",
    "# Load the GLOVE embeddings\n",
    "embedding_path = './glove.6B.300d.txt'\n",
    "embedding_index = {}\n",
    "with open(embedding_path, encoding='utf8') as f:\n",
    "    for line in f:\n",
    "        values = line.split()\n",
    "        word = values[0]\n",
    "        coefs = np.asarray(values[1:], dtype='float32')\n",
    "        embedding_index[word] = coefs\n",
    "\n",
    "# Define the tokenizer and fit on the text data\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "\n",
    "# Convert the text to sequences of integers and pad to a length of 100\n",
    "X_train_sequences = tokenizer.texts_to_sequences(X_train)\n",
    "X_train_padded = pad_sequences(X_train_sequences, maxlen=100)\n",
    "\n",
    "X_test_sequences = tokenizer.texts_to_sequences(X_test)\n",
    "X_test_padded = pad_sequences(X_test_sequences, maxlen=100)\n",
    "\n",
    "X_val_sequences = tokenizer.texts_to_sequences(X_val)\n",
    "X_val_padded = pad_sequences(X_val_sequences, maxlen=100)\n",
    "\n",
    "# Create an embedding matrix for the words in the tokenizer\n",
    "word_index = tokenizer.word_index\n",
    "embedding_dim = 300\n",
    "num_words = len(word_index) + 1\n",
    "embedding_matrix = np.zeros((num_words, embedding_dim))\n",
    "for word, i in word_index.items():\n",
    "    embedding_vector = embedding_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "    else:\n",
    "        embedding_matrix[i] = np.random.normal(size=(embedding_dim,))\n",
    "\n",
    "# Convert the labels to one-hot encoding\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "enc = OneHotEncoder()\n",
    "Y_train = enc.fit_transform(np.array(Y_train).reshape(-1, 1)).toarray()\n",
    "Y_test = enc.transform(np.array(Y_test).reshape(-1, 1)).toarray()\n",
    "Y_val = enc.transform(np.array(Y_val).reshape(-1, 1)).toarray()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def categorical_accuracy_scorer(estimator, X, y):\n",
    "    y_pred = estimator.predict(X)\n",
    "    y_true = np.argmax(y, axis=1)\n",
    "    return accuracy_score(y_true, y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Create a dummy adjacency matrix for demonstration purposes\n",
    "adj_matrix = np.zeros((X_train_padded.shape[0], 100, 100))\n",
    "\n",
    "for i in range(X_train_padded.shape[0]):\n",
    "    for j in range(100):\n",
    "        adj_matrix[i, j, (j+1) % 100] = 1\n",
    "        adj_matrix[i, j, (j-1) % 100] = 1\n",
    "\n",
    "adj_matrix_val = np.zeros((X_val_padded.shape[0], 100, 100))\n",
    "\n",
    "for i in range(X_val_padded.shape[0]):\n",
    "    for j in range(100):\n",
    "        adj_matrix_val[i, j, (j+1) % 100] = 1\n",
    "        adj_matrix_val[i, j, (j-1) % 100] = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "69/69 [==============================] - 2s 9ms/step - loss: 1.4189 - accuracy: 0.3688 - val_loss: 1.0671 - val_accuracy: 0.4776\n",
      "Epoch 2/50\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 1.1455 - accuracy: 0.4594 - val_loss: 1.0025 - val_accuracy: 0.4925\n",
      "Epoch 3/50\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 1.0291 - accuracy: 0.5206 - val_loss: 0.9758 - val_accuracy: 0.5336\n",
      "Epoch 4/50\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 0.9610 - accuracy: 0.5668 - val_loss: 0.9739 - val_accuracy: 0.5336\n",
      "Epoch 5/50\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 0.9145 - accuracy: 0.5877 - val_loss: 0.9646 - val_accuracy: 0.5448\n",
      "Epoch 6/50\n",
      "69/69 [==============================] - 1s 7ms/step - loss: 0.8758 - accuracy: 0.6035 - val_loss: 0.9598 - val_accuracy: 0.5410\n",
      "Epoch 7/50\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 0.8415 - accuracy: 0.6285 - val_loss: 0.9426 - val_accuracy: 0.5560\n",
      "Epoch 8/50\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 0.8132 - accuracy: 0.6488 - val_loss: 0.9359 - val_accuracy: 0.5560\n",
      "Epoch 9/50\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 0.7851 - accuracy: 0.6629 - val_loss: 0.9359 - val_accuracy: 0.5672\n",
      "Epoch 10/50\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 0.7634 - accuracy: 0.6769 - val_loss: 0.9329 - val_accuracy: 0.5672\n",
      "Epoch 11/50\n",
      "69/69 [==============================] - 1s 8ms/step - loss: 0.7333 - accuracy: 0.6815 - val_loss: 0.9265 - val_accuracy: 0.5746\n",
      "Epoch 12/50\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 0.7177 - accuracy: 0.6905 - val_loss: 0.9287 - val_accuracy: 0.5709\n",
      "Epoch 13/50\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 0.7022 - accuracy: 0.7010 - val_loss: 0.9190 - val_accuracy: 0.5784\n",
      "Epoch 14/50\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 0.6663 - accuracy: 0.7227 - val_loss: 0.9192 - val_accuracy: 0.5933\n",
      "Epoch 15/50\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 0.6362 - accuracy: 0.7295 - val_loss: 0.9291 - val_accuracy: 0.5933\n",
      "Epoch 16/50\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 0.6315 - accuracy: 0.7399 - val_loss: 0.9292 - val_accuracy: 0.5709\n",
      "Epoch 17/50\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 0.6121 - accuracy: 0.7381 - val_loss: 0.9193 - val_accuracy: 0.5821\n",
      "Epoch 18/50\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 0.5774 - accuracy: 0.7517 - val_loss: 0.9176 - val_accuracy: 0.6007\n",
      "Epoch 19/50\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 0.5830 - accuracy: 0.7671 - val_loss: 0.9171 - val_accuracy: 0.5858\n",
      "Epoch 20/50\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 0.5496 - accuracy: 0.7725 - val_loss: 0.9223 - val_accuracy: 0.5821\n",
      "Epoch 21/50\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 0.5403 - accuracy: 0.7825 - val_loss: 0.9208 - val_accuracy: 0.5784\n",
      "Epoch 22/50\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 0.4979 - accuracy: 0.8002 - val_loss: 0.9290 - val_accuracy: 0.5784\n",
      "Epoch 23/50\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 0.4789 - accuracy: 0.8038 - val_loss: 0.9223 - val_accuracy: 0.5896\n",
      "Epoch 24/50\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 0.4712 - accuracy: 0.8092 - val_loss: 0.9228 - val_accuracy: 0.5746\n",
      "Epoch 25/50\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 0.4548 - accuracy: 0.8083 - val_loss: 0.9226 - val_accuracy: 0.5784\n",
      "Epoch 26/50\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 0.4395 - accuracy: 0.8328 - val_loss: 0.9326 - val_accuracy: 0.5746\n",
      "Epoch 27/50\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 0.4347 - accuracy: 0.8265 - val_loss: 0.9285 - val_accuracy: 0.5858\n",
      "Epoch 28/50\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 0.4160 - accuracy: 0.8387 - val_loss: 0.9419 - val_accuracy: 0.5970\n",
      "Epoch 29/50\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 0.3927 - accuracy: 0.8473 - val_loss: 0.9359 - val_accuracy: 0.5709\n",
      "Epoch 30/50\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 0.3817 - accuracy: 0.8514 - val_loss: 0.9442 - val_accuracy: 0.5746\n",
      "Epoch 31/50\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 0.3792 - accuracy: 0.8532 - val_loss: 0.9300 - val_accuracy: 0.5933\n",
      "Epoch 32/50\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 0.3392 - accuracy: 0.8700 - val_loss: 0.9367 - val_accuracy: 0.5746\n",
      "Epoch 33/50\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 0.3378 - accuracy: 0.8695 - val_loss: 0.9298 - val_accuracy: 0.5709\n",
      "Epoch 34/50\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 0.3311 - accuracy: 0.8772 - val_loss: 0.9410 - val_accuracy: 0.5858\n",
      "Epoch 35/50\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 0.3179 - accuracy: 0.8772 - val_loss: 0.9387 - val_accuracy: 0.5522\n",
      "Epoch 36/50\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 0.3161 - accuracy: 0.8713 - val_loss: 0.9600 - val_accuracy: 0.5522\n",
      "Epoch 37/50\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 0.2968 - accuracy: 0.8953 - val_loss: 0.9621 - val_accuracy: 0.5485\n",
      "Epoch 38/50\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 0.2870 - accuracy: 0.8940 - val_loss: 0.9594 - val_accuracy: 0.5522\n",
      "Epoch 39/50\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 0.2893 - accuracy: 0.8990 - val_loss: 0.9759 - val_accuracy: 0.5448\n",
      "Epoch 40/50\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 0.3012 - accuracy: 0.8840 - val_loss: 0.9819 - val_accuracy: 0.5672\n",
      "Epoch 41/50\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 0.2911 - accuracy: 0.8913 - val_loss: 0.9580 - val_accuracy: 0.5522\n",
      "Epoch 42/50\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 0.2720 - accuracy: 0.8949 - val_loss: 0.9716 - val_accuracy: 0.5336\n",
      "Epoch 43/50\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 0.2532 - accuracy: 0.9098 - val_loss: 0.9827 - val_accuracy: 0.5485\n",
      "Epoch 44/50\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 0.2552 - accuracy: 0.9048 - val_loss: 0.9877 - val_accuracy: 0.5522\n",
      "Epoch 45/50\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 0.2467 - accuracy: 0.9085 - val_loss: 0.9777 - val_accuracy: 0.5597\n",
      "Epoch 46/50\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 0.2369 - accuracy: 0.9135 - val_loss: 1.0040 - val_accuracy: 0.5672\n",
      "Epoch 47/50\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 0.2123 - accuracy: 0.9289 - val_loss: 1.0083 - val_accuracy: 0.5560\n",
      "Epoch 48/50\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 0.2061 - accuracy: 0.9334 - val_loss: 1.0005 - val_accuracy: 0.5634\n",
      "Epoch 49/50\n",
      "69/69 [==============================] - 0s 6ms/step - loss: 0.2312 - accuracy: 0.9139 - val_loss: 1.0018 - val_accuracy: 0.5336\n",
      "Epoch 50/50\n",
      "69/69 [==============================] - 0s 7ms/step - loss: 0.2042 - accuracy: 0.9271 - val_loss: 1.0056 - val_accuracy: 0.5560\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Input, Embedding, Dense, BatchNormalization, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from spektral.layers import GCNConv, GlobalSumPool\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "# Define the GCN model\n",
    "input_layer = Input(shape=(100,))\n",
    "embedding_layer = Embedding(input_dim=num_words, output_dim=embedding_dim, weights=[embedding_matrix], input_length=100, trainable=False)(input_layer)\n",
    "gcn1 = GCNConv(32, activation='relu')([embedding_layer, input_layer])\n",
    "pooling_layer = GlobalSumPool()(gcn1)\n",
    "dense_layer = Dense(128, activation='relu')(pooling_layer)\n",
    "batch_norm_layer = BatchNormalization()(dense_layer)\n",
    "dropout_layer = Dropout(0.2)(batch_norm_layer)\n",
    "output_layer = Dense(3, activation='softmax')(dropout_layer)\n",
    "model = Model(inputs=input_layer, outputs=output_layer)\n",
    "\n",
    "# Compile the model\n",
    "optimizer = Adam(learning_rate=0.0005)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "# history = model.fit(x=X_train_padded, y=Y_train, validation_data=(X_val_padded, Y_val), batch_size=32, epochs=50, callbacks=[early_stopping])\n",
    "history = model.fit(x=X_train_padded, y=Y_train, validation_data=(X_val_padded, Y_val), batch_size=32, epochs=50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 0s 4ms/step - loss: 0.8834 - accuracy: 0.5876\n",
      "Test loss: 0.8834083080291748\n",
      "Test accuracy: 0.5875576138496399\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the test set\n",
    "test_loss, test_acc = model.evaluate(X_test_padded, Y_test)\n",
    "print('Test loss:', test_loss)\n",
    "print('Test accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from tensorflow.keras.utils import Sequence\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
    "\n",
    "class DataGenerator(Sequence):\n",
    "    def __init__(self, X_text, X_image_paths, Y, batch_size=32, img_size=(224, 224), shuffle=True):\n",
    "        self.X_text = X_text\n",
    "        self.X_image_paths = X_image_paths\n",
    "        self.Y = Y\n",
    "        self.batch_size = batch_size\n",
    "        self.img_size = img_size\n",
    "        self.shuffle = shuffle\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.floor(len(self.X_text) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        indexes = self.indexes[index * self.batch_size:(index + 1) * self.batch_size]\n",
    "        X_text_temp = [self.X_text[k] for k in indexes]\n",
    "        X_image_paths_temp = [self.X_image_paths[k] for k in indexes]\n",
    "        Y_temp = [self.Y[k] for k in indexes]\n",
    "\n",
    "        X_text_batch = np.array(X_text_temp)\n",
    "        X_image_batch = self.__generate_image_data(X_image_paths_temp)\n",
    "        Y_batch = np.array(Y_temp)\n",
    "\n",
    "        return [X_text_batch, X_image_batch], Y_batch\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        self.indexes = np.arange(len(self.X_text))\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.indexes)\n",
    "\n",
    "    def __generate_image_data(self, image_paths):\n",
    "        images = []\n",
    "        for path in image_paths:\n",
    "            img = cv2.imread(path)\n",
    "            img = cv2.resize(img, self.img_size)\n",
    "            img = preprocess_input(img)\n",
    "            images.append(img)\n",
    "        return np.array(images)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MGNNS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "\n",
    "def load_data(file_path):\n",
    "    X_text_data = []\n",
    "    X_image_paths_data = []\n",
    "    X_places = []\n",
    "    Y_data = []\n",
    "    with open(file_path, 'r') as f:\n",
    "        for line in f:\n",
    "            example = json.loads(line.strip())\n",
    "            X_text_data.append(example['text'])\n",
    "            X_image_paths_data.append('../'+example['image'])\n",
    "            X_places.append(example['places'])\n",
    "            Y_data.append(example['label'])\n",
    "    return X_text_data, X_image_paths_data, X_places, Y_data\n",
    "\n",
    "X_train_text, X_train_image_paths, X_train_places, Y_train = load_data('./train_all_anno.json')\n",
    "X_test_text, X_test_image_paths, X_test_places, Y_test = load_data('./test_all_anno.json')\n",
    "X_val_text, X_val_image_paths, X_val_places, Y_val = load_data('./val_all_anno.json')\n",
    "\n",
    "X_train = [x.lower() for x in X_train_text]\n",
    "X_test = [x.lower() for x in X_test_text]\n",
    "X_val = [x.lower() for x in X_val_text]\n",
    "\n",
    "\n",
    "def convert_scene_to_onehot(scene_list, num_scenes):\n",
    "    onehot_scene_list = []\n",
    "    for scene_ids in scene_list:\n",
    "        onehot_scene = np.zeros(num_scenes)\n",
    "        onehot_scene[scene_ids] = 1\n",
    "        onehot_scene_list.append(onehot_scene)\n",
    "    return np.array(onehot_scene_list)\n",
    "\n",
    "num_scenes = 365  # 根据 place365 训练集中的总场景数设置\n",
    "\n",
    "# 将场景ID列表转换为 one-hot 编码\n",
    "X_train_places_onehot = convert_scene_to_onehot(X_train_places, num_scenes)\n",
    "X_test_places_onehot = convert_scene_to_onehot(X_test_places, num_scenes)\n",
    "X_val_places_onehot = convert_scene_to_onehot(X_val_places, num_scenes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from tensorflow.keras.utils import Sequence\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
    "\n",
    "class DataGenerator(Sequence):\n",
    "    def __init__(self, X_text, X_image_paths, X_places_onehot, Y, batch_size=32, img_size=(224, 224), shuffle=True):\n",
    "        self.X_text = X_text\n",
    "        self.X_image_paths = X_image_paths\n",
    "        self.X_places_onehot = X_places_onehot\n",
    "        self.Y = Y\n",
    "        self.batch_size = batch_size\n",
    "        self.img_size = img_size\n",
    "        self.shuffle = shuffle\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.floor(len(self.X_text) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        indexes = self.indexes[index * self.batch_size:(index + 1) * self.batch_size]\n",
    "        X_text_temp = [self.X_text[k] for k in indexes]\n",
    "        X_image_paths_temp = [self.X_image_paths[k] for k in indexes]\n",
    "        X_places_temp = [self.X_places_onehot[k] for k in indexes]\n",
    "        Y_temp = [self.Y[k] for k in indexes]\n",
    "\n",
    "        X_text_batch = np.array(X_text_temp)\n",
    "        X_image_batch = self.__generate_image_data(X_image_paths_temp)\n",
    "        X_places_batch = np.array(X_places_temp)\n",
    "        Y_batch = np.array(Y_temp)\n",
    "\n",
    "        return [X_text_batch, X_image_batch, X_places_batch], Y_batch\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        self.indexes = np.arange(len(self.X_text))\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.indexes)\n",
    "\n",
    "    def __generate_image_data(self, image_paths):\n",
    "        images = []\n",
    "        for path in image_paths:\n",
    "            img = cv2.imread(path)\n",
    "            img = cv2.resize(img, self.img_size)\n",
    "            img = preprocess_input(img)\n",
    "            images.append(img)\n",
    "        return np.array(images)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import numpy as np\n",
    "\n",
    "# Load the GLOVE embeddings\n",
    "embedding_path = './glove.6B.300d.txt'\n",
    "embedding_index = {}\n",
    "with open(embedding_path, encoding='utf8') as f:\n",
    "    for line in f:\n",
    "        values = line.split()\n",
    "        word = values[0]\n",
    "        coefs = np.asarray(values[1:], dtype='float32')\n",
    "        embedding_index[word] = coefs\n",
    "\n",
    "# Define the tokenizer and fit on the text data\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "\n",
    "# Convert the text to sequences of integers and pad to a length of 100\n",
    "X_train_sequences = tokenizer.texts_to_sequences(X_train)\n",
    "X_train_padded = pad_sequences(X_train_sequences, maxlen=100)\n",
    "\n",
    "X_test_sequences = tokenizer.texts_to_sequences(X_test)\n",
    "X_test_padded = pad_sequences(X_test_sequences, maxlen=100)\n",
    "\n",
    "X_val_sequences = tokenizer.texts_to_sequences(X_val)\n",
    "X_val_padded = pad_sequences(X_val_sequences, maxlen=100)\n",
    "\n",
    "# Create an embedding matrix for the words in the tokenizer\n",
    "word_index = tokenizer.word_index\n",
    "embedding_dim = 300\n",
    "num_words = len(word_index) + 1\n",
    "embedding_matrix = np.zeros((num_words, embedding_dim))\n",
    "for word, i in word_index.items():\n",
    "    embedding_vector = embedding_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "    else:\n",
    "        embedding_matrix[i] = np.random.normal(size=(embedding_dim,))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelBinarizer\n",
    "lb = LabelBinarizer()\n",
    "Y_train_encoded = lb.fit_transform(Y_train)\n",
    "Y_val_encoded = lb.transform(Y_val)\n",
    "Y_test_encoded = lb.transform(Y_test)\n",
    "\n",
    "train_generator = DataGenerator(X_train_padded, X_train_image_paths, X_train_places_onehot, Y_train_encoded, batch_size=32)\n",
    "val_generator = DataGenerator(X_val_padded, X_val_image_paths, X_val_places_onehot, Y_val_encoded, batch_size=32)\n",
    "test_generator = DataGenerator(X_test_padded, X_test_image_paths, X_test_places_onehot, Y_test_encoded, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import backend as K\n",
    "\n",
    "def f1_score(y_true, y_pred): \n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    f1_val = 2*(precision*recall)/(precision+recall+K.epsilon())\n",
    "    return f1_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, Embedding, Dense, BatchNormalization, Dropout, Conv2D, Concatenate, MultiHeadAttention\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Reshape, Dense, Conv2DTranspose\n",
    "from spektral.layers import GCNConv, GlobalSumPool\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, MaxPooling2D, Flatten, Add, Reshape, GlobalAveragePooling1D\n",
    "\n",
    "num_scenes = 5  # 根据场景数量设置\n",
    "scene_dim = 32  # 嵌入维度\n",
    "\n",
    "# Text input\n",
    "text_input_layer = Input(shape=(100,))\n",
    "\n",
    "# Image input\n",
    "image_input_layer = Input(shape=(224, 224, 3))\n",
    "\n",
    "# Scene input\n",
    "scene_input_layer = Input(shape=(num_scenes,))\n",
    "\n",
    "# Text model\n",
    "embedding_layer = Embedding(input_dim=num_words, output_dim=embedding_dim, weights=[embedding_matrix], input_length=100, trainable=False)(text_input_layer)\n",
    "gcn1 = GCNConv(32, activation='relu')([embedding_layer, text_input_layer])\n",
    "text_pooling_layer = GlobalSumPool()(gcn1)\n",
    "\n",
    "# Image model\n",
    "base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))(image_input_layer)\n",
    "\n",
    "# Scene model\n",
    "scene_embedding_layer = Embedding(input_dim=num_scenes, output_dim=scene_dim, input_length=num_scenes)(scene_input_layer)\n",
    "scene_gcn = GCNConv(32, activation='relu')([scene_embedding_layer, scene_input_layer])\n",
    "scene_pooling_layer = GlobalSumPool()(scene_gcn)\n",
    "\n",
    "# Prepare attention layers\n",
    "text_dim = 64\n",
    "image_dim = 64\n",
    "scene_dim = 64\n",
    "\n",
    "text_features = Dense(text_dim)(text_pooling_layer)\n",
    "image_features = Dense(image_dim)(base_model)\n",
    "scene_features = Dense(scene_dim)(scene_pooling_layer)\n",
    "\n",
    "# 将图像特征降维以便拼接\n",
    "image_features = GlobalAveragePooling2D()(image_features)\n",
    "\n",
    "# Concatenate the features\n",
    "concat_layer = Concatenate()([text_features, image_features, scene_features])\n",
    "\n",
    "# 添加一个或多个全连接层\n",
    "dense_layer1 = Dense(256, activation='relu')(concat_layer)\n",
    "batch_norm_layer1 = BatchNormalization()(dense_layer1)\n",
    "dropout_layer1 = Dropout(0.2)(batch_norm_layer1)\n",
    "\n",
    "dense_layer2 = Dense(128, activation='relu')(dropout_layer1)\n",
    "batch_norm_layer2 = BatchNormalization()(dense_layer2)\n",
    "dropout_layer2 = Dropout(0.2)(batch_norm_layer2)\n",
    "\n",
    "# Classification head\n",
    "output_layer = Dense(3, activation='softmax')(dropout_layer2)\n",
    "\n",
    "model = Model(inputs=[text_input_layer, image_input_layer, scene_input_layer], outputs=output_layer)\n",
    "\n",
    "optimizer = Adam(learning_rate=0.0005)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy', f1_score])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "68/68 [==============================] - 673s 10s/step - loss: 0.8084 - accuracy: 0.6342 - f1_score: 0.6069 - val_loss: 1.0160 - val_accuracy: 0.5508 - val_f1_score: 0.4861\n",
      "Epoch 2/50\n",
      "68/68 [==============================] - 737s 11s/step - loss: 0.7899 - accuracy: 0.6562 - f1_score: 0.6404 - val_loss: 0.9452 - val_accuracy: 0.5312 - val_f1_score: 0.5108\n",
      "Epoch 3/50\n",
      "66/68 [============================>.] - ETA: 27s - loss: 0.7578 - accuracy: 0.6785 - f1_score: 0.6572"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# Define early stopping callback\n",
    "early_stopping = EarlyStopping(monitor='val_f1_score', patience=5, restore_best_weights=True, mode='max')\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(train_generator, epochs=50, validation_data=val_generator, callbacks=[early_stopping])\n",
    "# history = model.fit(train_generator, epochs=50, validation_data=val_generator)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 25s 2s/step - loss: 0.9458 - accuracy: 0.4784 - f1_score: 0.3706\n",
      "Test loss: 0.9458478689193726, Test accuracy: 0.47836539149284363, Test F1-score: 0.3706305921077728\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the test set\n",
    "test_loss, test_accuracy, test_f1_score = model.evaluate(test_generator)\n",
    "print(f\"Test loss: {test_loss}, Test accuracy: {test_accuracy}, Test F1-score: {test_f1_score}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MGNNS",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
