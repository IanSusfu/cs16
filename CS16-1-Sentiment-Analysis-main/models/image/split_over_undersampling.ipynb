{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "43f583ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the folder paths and dataset CSV path (customize these according to your setup)\n",
    "image_folder = 'C:\\\\Users\\\\Jeffan\\\\Downloads\\\\MVSA-Single\\\\MVSA_Single\\\\data'\n",
    "dataset_csv = 'C:\\\\Users\\\\Jeffan\\\\Documents\\\\GitHub\\\\CS16-1-Sentiment-Analysis\\\\Data Image\\\\output_single.csv'\n",
    "train_folder = 'C:\\\\Users\\\\Jeffan\\\\Downloads\\\\MVSA-Single\\\\MVSA_Single\\\\train'\n",
    "val_folder = 'C:\\\\Users\\\\Jeffan\\\\Downloads\\\\MVSA-Single\\\\MVSA_Single\\\\val'\n",
    "test_folder = 'C:\\\\Users\\\\Jeffan\\\\Downloads\\\\MVSA-Single\\\\MVSA_Single\\\\test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "38cf4bc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'image'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ids = []\n",
    "texts = []\n",
    "images = []\n",
    "with open('C:\\\\Users\\\\Jeffan\\\\Downloads\\\\MVSA-Single\\\\MVSA_Single\\\\labelResultAll.txt', 'r', encoding='ISO-8859-1') as file:\n",
    "    for line in file:\n",
    "        text_list = line.replace('\\n','').split('\t')\n",
    "        text_label = text_list[1].split(',')[0]\n",
    "        image_label = text_list[1].split(',')[1]\n",
    "        if not ((text_label=='positive' and image_label=='negative') or (text_label=='positive' and image_label=='negative')):\n",
    "            ids.append(text_list[0])\n",
    "            texts.append(text_label)\n",
    "            images.append(image_label)\n",
    "ids.pop(0)\n",
    "texts.pop(0)\n",
    "images.pop(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bbc84817",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Text</th>\n",
       "      <th>Image</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>neutral</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>neutral</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>neutral</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4786</th>\n",
       "      <td>5125</td>\n",
       "      <td>neutral</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4787</th>\n",
       "      <td>5126</td>\n",
       "      <td>positive</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4788</th>\n",
       "      <td>5127</td>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4789</th>\n",
       "      <td>5128</td>\n",
       "      <td>neutral</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4790</th>\n",
       "      <td>5129</td>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4791 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        ID      Text     Image\n",
       "0        1   neutral  positive\n",
       "1        2   neutral  positive\n",
       "2        3   neutral  positive\n",
       "3        4  positive  positive\n",
       "4        5  positive  positive\n",
       "...    ...       ...       ...\n",
       "4786  5125   neutral  positive\n",
       "4787  5126  positive   neutral\n",
       "4788  5127  positive  positive\n",
       "4789  5128   neutral  positive\n",
       "4790  5129  positive  positive\n",
       "\n",
       "[4791 rows x 3 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "dataset = {'ID':ids, 'Text':texts, 'Image':images}\n",
    "df = pd.DataFrame(dataset)\n",
    "df.to_csv('output_single.csv', index=False)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "eb447ea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import shutil\n",
    "\n",
    "def oversample_minority_classes(df, folder):\n",
    "    class_counts = df['Image'].value_counts()\n",
    "    max_count = class_counts.max()\n",
    "\n",
    "    for cls, count in class_counts.items():\n",
    "        if count < max_count:\n",
    "            cls_df = df[df['Image'] == cls]\n",
    "            num_samples_needed = round(max_count*0.7) - count\n",
    "\n",
    "            for i in range(num_samples_needed):\n",
    "                row = cls_df.sample().iloc[0]\n",
    "                original_image_path = os.path.join(folder, row['Image'], f\"{row['ID']}.jpg\")\n",
    "                new_image_id = f\"{row['ID']}_oversampled_{i}\"\n",
    "                new_image_path = os.path.join(folder, row['Image'], f\"{new_image_id}.jpg\")\n",
    "                shutil.copy(original_image_path, new_image_path)\n",
    "                new_row = row.copy()\n",
    "                new_row['ID'] = new_image_id\n",
    "                df = df.append(new_row, ignore_index=True)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "57c9e9c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.pipeline import Pipeline\n",
    "\n",
    "def split_balanced_images(image_folder, dataset_csv, train_folder, val_folder, test_folder, ratio=(8, 1, 1)):\n",
    "    # Read the dataset CSV file\n",
    "    df = pd.read_csv(dataset_csv)\n",
    "\n",
    "    # Shuffle the dataset\n",
    "    df = df.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "    # Create the output folders if they don't exist\n",
    "    os.makedirs(train_folder, exist_ok=True)\n",
    "    os.makedirs(val_folder, exist_ok=True)\n",
    "    os.makedirs(test_folder, exist_ok=True)\n",
    "\n",
    "    unique_classes = df['Image'].unique()\n",
    "\n",
    "    # Create class subfolders in train, val, and test folders\n",
    "    for cls in unique_classes:\n",
    "        os.makedirs(os.path.join(train_folder, cls), exist_ok=True)\n",
    "        os.makedirs(os.path.join(val_folder, cls), exist_ok=True)\n",
    "        os.makedirs(os.path.join(test_folder, cls), exist_ok=True)\n",
    "    \n",
    "    train_val_ratio = (ratio[0] + ratio[1]) / sum(ratio)\n",
    "    train_ratio = ratio[0] / (ratio[0] + ratio[1])\n",
    "\n",
    "    train_val_df, test_df = train_test_split(df, test_size=1 - train_val_ratio, stratify=df['Image'], random_state=42)\n",
    "    train_df, val_df = train_test_split(train_val_df, test_size=1 - train_ratio, stratify=train_val_df['Image'], random_state=42)\n",
    "\n",
    "    # Define the undersampling strategy\n",
    "    undersample = RandomUnderSampler(sampling_strategy='majority')\n",
    "\n",
    "    # Encode class labels\n",
    "    encoder = LabelEncoder()\n",
    "    train_val_df['Image'] = encoder.fit_transform(train_val_df['Image'])\n",
    "    train_df['Image'] = encoder.transform(train_df['Image'])\n",
    "    val_df['Image'] = encoder.transform(val_df['Image'])\n",
    "\n",
    "    # Undersample the training set\n",
    "    X_train = train_df.drop(columns=['Image'])\n",
    "    y_train = train_df['Image']\n",
    "    X_train_resampled, y_train_resampled = undersample.fit_resample(X_train, y_train)\n",
    "    train_df_resampled = pd.concat([X_train_resampled, y_train_resampled], axis=1)\n",
    "\n",
    "    # Undersample the validation set\n",
    "    X_val = val_df.drop(columns=['Image'])\n",
    "    y_val = val_df['Image']\n",
    "    X_val_resampled, y_val_resampled = undersample.fit_resample(X_val, y_val)\n",
    "    val_df_resampled = pd.concat([X_val_resampled, y_val_resampled], axis=1)\n",
    "\n",
    "    # Decode class labels\n",
    "    train_df_resampled['Image'] = encoder.inverse_transform(train_df_resampled['Image'])\n",
    "    val_df_resampled['Image'] = encoder.inverse_transform(val_df_resampled['Image'])\n",
    "\n",
    "    # Move the images to the corresponding class subfolders\n",
    "    for _, row in train_df_resampled.iterrows():\n",
    "        shutil.copy(os.path.join(image_folder, f\"{row['ID']}.jpg\"), os.path.join(train_folder, row['Image'], f\"{row['ID']}.jpg\"))\n",
    "    for _, row in val_df_resampled.iterrows():\n",
    "        shutil.copy(os.path.join(image_folder, f\"{row['ID']}.jpg\"), os.path.join(val_folder, row['Image'], f\"{row['ID']}.jpg\"))\n",
    "    for _, row in test_df.iterrows():\n",
    "        shutil.copy(os.path.join(image_folder, f\"{row['ID']}.jpg\"), os.path.join(test_folder, row['Image'], f\"{row['ID']}.jpg\"))\n",
    "\n",
    "# Split the images\n",
    "split_balanced_images(image_folder, dataset_csv, train_folder, val_folder, test_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7c227cbf",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'type_spec_registry' from 'tensorflow.python.framework' (c:\\Users\\Jeffan\\.conda\\envs\\capstone2\\lib\\site-packages\\tensorflow\\python\\framework\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[27], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpreprocessing\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mimage\u001b[39;00m \u001b[39mimport\u001b[39;00m ImageDataGenerator\n\u001b[0;32m      2\u001b[0m train_datagen \u001b[39m=\u001b[39m ImageDataGenerator(\n\u001b[0;32m      3\u001b[0m     rescale\u001b[39m=\u001b[39m\u001b[39m1.\u001b[39m\u001b[39m/\u001b[39m\u001b[39m255\u001b[39m,\n\u001b[0;32m      4\u001b[0m     shear_range\u001b[39m=\u001b[39m\u001b[39m0.2\u001b[39m,\n\u001b[0;32m      5\u001b[0m     zoom_range\u001b[39m=\u001b[39m\u001b[39m0.2\u001b[39m,\n\u001b[0;32m      6\u001b[0m     horizontal_flip\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m\n\u001b[0;32m      7\u001b[0m )\n\u001b[0;32m      9\u001b[0m train_generator \u001b[39m=\u001b[39m train_datagen\u001b[39m.\u001b[39mflow_from_directory(\n\u001b[0;32m     10\u001b[0m     directory\u001b[39m=\u001b[39m train_folder,\n\u001b[0;32m     11\u001b[0m     target_size\u001b[39m=\u001b[39m(\u001b[39m224\u001b[39m, \u001b[39m224\u001b[39m),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     14\u001b[0m     shuffle\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m\n\u001b[0;32m     15\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\Jeffan\\.conda\\envs\\capstone2\\lib\\site-packages\\keras\\__init__.py:21\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[39m\"\"\"Implementation of the Keras API, the high-level API of TensorFlow.\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \n\u001b[0;32m     17\u001b[0m \u001b[39mDetailed documentation and user guides are available at\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \u001b[39m[keras.io](https://keras.io).\u001b[39;00m\n\u001b[0;32m     19\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m     20\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m \u001b[39mimport\u001b[39;00m distribute\n\u001b[1;32m---> 21\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m \u001b[39mimport\u001b[39;00m models\n\u001b[0;32m     22\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mengine\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39minput_layer\u001b[39;00m \u001b[39mimport\u001b[39;00m Input\n\u001b[0;32m     23\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mengine\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msequential\u001b[39;00m \u001b[39mimport\u001b[39;00m Sequential\n",
      "File \u001b[1;32mc:\\Users\\Jeffan\\.conda\\envs\\capstone2\\lib\\site-packages\\keras\\models\\__init__.py:18\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# Copyright 2022 The TensorFlow Authors. All Rights Reserved.\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[39m#\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[39m# Licensed under the Apache License, Version 2.0 (the \"License\");\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[39m# limitations under the License.\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \u001b[39m# ==============================================================================\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[39m\"\"\"Keras models API.\"\"\"\u001b[39;00m\n\u001b[1;32m---> 18\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mengine\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mfunctional\u001b[39;00m \u001b[39mimport\u001b[39;00m Functional\n\u001b[0;32m     19\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mengine\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msequential\u001b[39;00m \u001b[39mimport\u001b[39;00m Sequential\n\u001b[0;32m     20\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mengine\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtraining\u001b[39;00m \u001b[39mimport\u001b[39;00m Model\n",
      "File \u001b[1;32mc:\\Users\\Jeffan\\.conda\\envs\\capstone2\\lib\\site-packages\\keras\\engine\\functional.py:26\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mwarnings\u001b[39;00m\n\u001b[0;32m     24\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcompat\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mv2\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mtf\u001b[39;00m\n\u001b[1;32m---> 26\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m \u001b[39mimport\u001b[39;00m backend\n\u001b[0;32m     27\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdtensor\u001b[39;00m \u001b[39mimport\u001b[39;00m layout_map \u001b[39mas\u001b[39;00m layout_map_lib\n\u001b[0;32m     28\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mengine\u001b[39;00m \u001b[39mimport\u001b[39;00m base_layer\n",
      "File \u001b[1;32mc:\\Users\\Jeffan\\.conda\\envs\\capstone2\\lib\\site-packages\\keras\\backend.py:35\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdistribute\u001b[39;00m \u001b[39mimport\u001b[39;00m distribute_coordinator_utils \u001b[39mas\u001b[39;00m dc\n\u001b[0;32m     34\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdtensor\u001b[39;00m \u001b[39mimport\u001b[39;00m dtensor_api \u001b[39mas\u001b[39;00m dtensor\n\u001b[1;32m---> 35\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mengine\u001b[39;00m \u001b[39mimport\u001b[39;00m keras_tensor\n\u001b[0;32m     36\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m \u001b[39mimport\u001b[39;00m control_flow_util\n\u001b[0;32m     37\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m \u001b[39mimport\u001b[39;00m object_identity\n",
      "File \u001b[1;32mc:\\Users\\Jeffan\\.conda\\envs\\capstone2\\lib\\site-packages\\keras\\engine\\keras_tensor.py:19\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[39m\"\"\"Keras Input Tensor used to track functional API Topology.\"\"\"\u001b[39;00m\n\u001b[0;32m     17\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcompat\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mv2\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mtf\u001b[39;00m\n\u001b[1;32m---> 19\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m \u001b[39mimport\u001b[39;00m object_identity\n\u001b[0;32m     21\u001b[0m \u001b[39m# isort: off\u001b[39;00m\n\u001b[0;32m     22\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdata\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutil\u001b[39;00m \u001b[39mimport\u001b[39;00m structure\n",
      "File \u001b[1;32mc:\\Users\\Jeffan\\.conda\\envs\\capstone2\\lib\\site-packages\\keras\\utils\\__init__.py:53\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdata_utils\u001b[39;00m \u001b[39mimport\u001b[39;00m get_file\n\u001b[0;32m     52\u001b[0m \u001b[39m# Preprocessing utils\u001b[39;00m\n\u001b[1;32m---> 53\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mfeature_space\u001b[39;00m \u001b[39mimport\u001b[39;00m FeatureSpace\n\u001b[0;32m     55\u001b[0m \u001b[39m# Internal\u001b[39;00m\n\u001b[0;32m     56\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlayer_utils\u001b[39;00m \u001b[39mimport\u001b[39;00m get_source_inputs\n",
      "File \u001b[1;32mc:\\Users\\Jeffan\\.conda\\envs\\capstone2\\lib\\site-packages\\keras\\utils\\feature_space.py:20\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcompat\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mv2\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mtf\u001b[39;00m\n\u001b[0;32m     19\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m \u001b[39mimport\u001b[39;00m backend\n\u001b[1;32m---> 20\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mengine\u001b[39;00m \u001b[39mimport\u001b[39;00m base_layer\n\u001b[0;32m     21\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msaving\u001b[39;00m \u001b[39mimport\u001b[39;00m saving_lib\n\u001b[0;32m     22\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msaving\u001b[39;00m \u001b[39mimport\u001b[39;00m serialization_lib\n",
      "File \u001b[1;32mc:\\Users\\Jeffan\\.conda\\envs\\capstone2\\lib\\site-packages\\keras\\engine\\base_layer.py:39\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mengine\u001b[39;00m \u001b[39mimport\u001b[39;00m input_spec\n\u001b[0;32m     38\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mengine\u001b[39;00m \u001b[39mimport\u001b[39;00m keras_tensor\n\u001b[1;32m---> 39\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mengine\u001b[39;00m \u001b[39mimport\u001b[39;00m node \u001b[39mas\u001b[39;00m node_module\n\u001b[0;32m     40\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmixed_precision\u001b[39;00m \u001b[39mimport\u001b[39;00m autocast_variable\n\u001b[0;32m     41\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmixed_precision\u001b[39;00m \u001b[39mimport\u001b[39;00m loss_scale_optimizer\n",
      "File \u001b[1;32mc:\\Users\\Jeffan\\.conda\\envs\\capstone2\\lib\\site-packages\\keras\\engine\\node.py:28\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m \u001b[39mimport\u001b[39;00m backend\n\u001b[0;32m     27\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mengine\u001b[39;00m \u001b[39mimport\u001b[39;00m base_layer_utils\n\u001b[1;32m---> 28\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msaving\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlegacy\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msaved_model\u001b[39;00m \u001b[39mimport\u001b[39;00m json_utils\n\u001b[0;32m     29\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m \u001b[39mimport\u001b[39;00m tf_utils\n\u001b[0;32m     31\u001b[0m _CONSTANT_VALUE \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m_CONSTANT_VALUE\u001b[39m\u001b[39m\"\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\Jeffan\\.conda\\envs\\capstone2\\lib\\site-packages\\keras\\saving\\legacy\\saved_model\\json_utils.py:36\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msaving\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlegacy\u001b[39;00m \u001b[39mimport\u001b[39;00m serialization\n\u001b[0;32m     35\u001b[0m \u001b[39m# isort: off\u001b[39;00m\n\u001b[1;32m---> 36\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mframework\u001b[39;00m \u001b[39mimport\u001b[39;00m type_spec_registry\n\u001b[0;32m     38\u001b[0m _EXTENSION_TYPE_SPEC \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m_EXTENSION_TYPE_SPEC\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m     41\u001b[0m \u001b[39mclass\u001b[39;00m \u001b[39mEncoder\u001b[39;00m(json\u001b[39m.\u001b[39mJSONEncoder):\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'type_spec_registry' from 'tensorflow.python.framework' (c:\\Users\\Jeffan\\.conda\\envs\\capstone2\\lib\\site-packages\\tensorflow\\python\\framework\\__init__.py)"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True\n",
    ")\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    directory= train_folder,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7223390f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    2166\n",
       "0    1516\n",
       "1    1516\n",
       "dtype: int64"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Index(train_generator.classes).value_counts()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
