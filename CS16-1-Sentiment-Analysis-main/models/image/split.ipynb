{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "43f583ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the folder paths and dataset CSV path (customize these according to your setup)\n",
    "image_folder = 'C:\\\\Users\\\\Jeffan\\\\Downloads\\\\MVSA-multiple\\\\MVSA\\\\data'\n",
    "dataset_csv = 'C:\\\\Users\\\\Jeffan\\\\Documents\\\\GitHub\\\\CS16-1-Sentiment-Analysis\\\\Data Image\\\\output_multi.csv'\n",
    "train_folder = 'C:\\\\Users\\\\Jeffan\\\\Downloads\\\\MVSA-multiple\\\\MVSA\\\\train'\n",
    "val_folder = 'C:\\\\Users\\\\Jeffan\\\\Downloads\\\\MVSA-multiple\\\\MVSA\\\\val'\n",
    "test_folder = 'C:\\\\Users\\\\Jeffan\\\\Downloads\\\\MVSA-multiple\\\\MVSA\\\\test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "38cf4bc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'image'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ids = []\n",
    "texts = []\n",
    "images = []\n",
    "with open('C:\\\\Users\\\\Jeffan\\\\Downloads\\\\MVSA-multiple\\\\MVSA\\\\labelResultAll.txt', 'r', encoding='ISO-8859-1') as file:\n",
    "    for line in file:\n",
    "        text_list = line.replace('\\n','').split('\t')\n",
    "        text_label_result = None\n",
    "        text_label_1 = text_list[1].split(',')[0]\n",
    "        text_label_2 = text_list[2].split(',')[0]\n",
    "        text_label_3 = text_list[3].split(',')[0]\n",
    "        if text_label_1 == text_label_2:\n",
    "            text_label_result = text_label_1\n",
    "        elif text_label_1 == text_label_3:\n",
    "            text_label_result = text_label_1\n",
    "        elif text_label_2 == text_label_3:\n",
    "            text_label_result = text_label_2\n",
    "\n",
    "        image_label_result = None\n",
    "        image_label_1 = text_list[1].split(',')[1]\n",
    "        image_label_2 = text_list[2].split(',')[1]\n",
    "        image_label_3 = text_list[3].split(',')[1]\n",
    "        if image_label_1 == image_label_2:\n",
    "            image_label_result = image_label_1\n",
    "        elif image_label_1 == image_label_3:\n",
    "            image_label_result = image_label_1\n",
    "        elif image_label_2 == image_label_3:\n",
    "            image_label_result = image_label_2\n",
    "\n",
    "        if not ((text_label_result=='positive' and image_label_result=='negative') or (text_label_result=='positive' and image_label_result=='negative')\n",
    "                or image_label_result is None or text_label_result is None):\n",
    "            ids.append(text_list[0])\n",
    "            texts.append(text_label_result)\n",
    "            images.append(image_label_result)\n",
    "ids.pop(0)\n",
    "texts.pop(0)\n",
    "images.pop(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bbc84817",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Text</th>\n",
       "      <th>Image</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2499</td>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2500</td>\n",
       "      <td>neutral</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2502</td>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2504</td>\n",
       "      <td>positive</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2505</td>\n",
       "      <td>positive</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17126</th>\n",
       "      <td>22885</td>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17127</th>\n",
       "      <td>22886</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17128</th>\n",
       "      <td>22888</td>\n",
       "      <td>positive</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17129</th>\n",
       "      <td>22889</td>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17130</th>\n",
       "      <td>22891</td>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17131 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          ID      Text     Image\n",
       "0       2499  positive  positive\n",
       "1       2500   neutral  positive\n",
       "2       2502  positive  positive\n",
       "3       2504  positive   neutral\n",
       "4       2505  positive   neutral\n",
       "...      ...       ...       ...\n",
       "17126  22885  positive  positive\n",
       "17127  22886   neutral   neutral\n",
       "17128  22888  positive   neutral\n",
       "17129  22889  positive  positive\n",
       "17130  22891  positive  positive\n",
       "\n",
       "[17131 rows x 3 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "dataset = {'ID':ids, 'Text':texts, 'Image':images}\n",
    "df = pd.DataFrame(dataset)\n",
    "df.to_csv('output_multi.csv', index=False)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eb447ea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import shutil\n",
    "\n",
    "def oversample_minority_classes(df, folder):\n",
    "    class_counts = df['Image'].value_counts()\n",
    "    max_count = class_counts.max()\n",
    "\n",
    "    for cls, count in class_counts.items():\n",
    "        if count < max_count:\n",
    "            cls_df = df[df['Image'] == cls]\n",
    "            num_samples_needed = round(max_count*0.7) - count\n",
    "\n",
    "            for i in range(num_samples_needed):\n",
    "                row = cls_df.sample().iloc[0]\n",
    "                original_image_path = os.path.join(folder, row['Image'], f\"{row['ID']}.jpg\")\n",
    "                new_image_id = f\"{row['ID']}_oversampled_{i}\"\n",
    "                new_image_path = os.path.join(folder, row['Image'], f\"{new_image_id}.jpg\")\n",
    "                shutil.copy(original_image_path, new_image_path)\n",
    "                new_row = row.copy()\n",
    "                new_row['ID'] = new_image_id\n",
    "                df = df.append(new_row, ignore_index=True)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "57c9e9c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jeffan\\AppData\\Local\\Temp\\ipykernel_11004\\1524181078.py:21: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Jeffan\\AppData\\Local\\Temp\\ipykernel_11004\\1524181078.py:21: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append(new_row, ignore_index=True)\n",
      "C:\\Users\\Jeffan\\AppData\\Local\\Temp\\ipykernel_11004\\1524181078.py:21: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append(new_row, ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def split_balanced_images(image_folder, dataset_csv, train_folder, val_folder, test_folder, ratio=(8, 1, 1)):\n",
    "    # Read the dataset CSV file\n",
    "    df = pd.read_csv(dataset_csv)\n",
    "\n",
    "    # Shuffle the dataset\n",
    "    df = df.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "    # Create the output folders if they don't exist\n",
    "    os.makedirs(train_folder, exist_ok=True)\n",
    "    os.makedirs(val_folder, exist_ok=True)\n",
    "    os.makedirs(test_folder, exist_ok=True)\n",
    "\n",
    "    unique_classes = df['Image'].unique()\n",
    "\n",
    "    # Create class subfolders in train, val, and test folders\n",
    "    for cls in unique_classes:\n",
    "        os.makedirs(os.path.join(train_folder, cls), exist_ok=True)\n",
    "        os.makedirs(os.path.join(val_folder, cls), exist_ok=True)\n",
    "        os.makedirs(os.path.join(test_folder, cls), exist_ok=True)\n",
    "    \n",
    "    train_val_ratio = (ratio[0] + ratio[1]) / sum(ratio)\n",
    "    train_ratio = ratio[0] / (ratio[0] + ratio[1])\n",
    "\n",
    "    train_df_final = pd.DataFrame()\n",
    "    val_df_final = pd.DataFrame()\n",
    "    test_df_final = pd.DataFrame()\n",
    "    # Perform stratified sampling and move the images to the corresponding class subfolders\n",
    "    for cls in unique_classes:\n",
    "        class_df = df[df['Image'] == cls]\n",
    "        train_val_df, test_df = train_test_split(class_df, test_size=1 - train_val_ratio, stratify=class_df['Image'], random_state=42)\n",
    "        train_df, val_df = train_test_split(train_val_df, test_size=1 - train_ratio, stratify=train_val_df['Image'], random_state=42)\n",
    "\n",
    "        for _, row in train_df.iterrows():\n",
    "            shutil.move(os.path.join(image_folder, f\"{row['ID']}.jpg\"), os.path.join(train_folder, row['Image'], f\"{row['ID']}.jpg\"))\n",
    "        for _, row in val_df.iterrows():\n",
    "            shutil.move(os.path.join(image_folder, f\"{row['ID']}.jpg\"), os.path.join(val_folder, row['Image'], f\"{row['ID']}.jpg\"))\n",
    "        for _, row in test_df.iterrows():\n",
    "            shutil.move(os.path.join(image_folder, f\"{row['ID']}.jpg\"), os.path.join(test_folder, row['Image'], f\"{row['ID']}.jpg\"))\n",
    "        train_df_final = pd.concat([train_df_final, train_df], axis=0)\n",
    "        val_df_final = pd.concat([val_df_final, val_df], axis=0)\n",
    "        test_df_final = pd.concat([test_df_final, test_df], axis=0)\n",
    "\n",
    "    # Oversample the minority classes in the train, validation, and test sets\n",
    "    train_df = oversample_minority_classes(train_df_final, train_folder)\n",
    "    val_df = oversample_minority_classes(val_df_final, val_folder)\n",
    "    test_df = oversample_minority_classes(test_df_final, test_folder)\n",
    "\n",
    "# Split the images\n",
    "split_balanced_images(image_folder, dataset_csv, train_folder, val_folder, test_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f9eb1e2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "def is_image_valid(image_path):\n",
    "    try:\n",
    "        with open(image_path, 'rb') as f:\n",
    "            img = Image.open(f)\n",
    "            img.verify()\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"Skipping invalid image {image_path}: {e}\")\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d96055e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping invalid image C:\\Users\\Jeffan\\Downloads\\MVSA-multiple\\MVSA\\data\\5995.jpg: cannot identify image file <_io.BufferedReader name='C:\\\\Users\\\\Jeffan\\\\Downloads\\\\MVSA-multiple\\\\MVSA\\\\data\\\\5995.jpg'>\n",
      "Skipping invalid image C:\\Users\\Jeffan\\Downloads\\MVSA-multiple\\MVSA\\data\\3910.jpg: cannot identify image file <_io.BufferedReader name='C:\\\\Users\\\\Jeffan\\\\Downloads\\\\MVSA-multiple\\\\MVSA\\\\data\\\\3910.jpg'>\n"
     ]
    }
   ],
   "source": [
    "def split_balanced_images(image_folder, dataset_csv, train_folder, val_folder, test_folder, ratio=(8, 1, 1)):\n",
    "    # Read the dataset CSV file\n",
    "    df = pd.read_csv(dataset_csv)\n",
    "\n",
    "    # Shuffle the dataset\n",
    "    df = df.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "    # Split the dataset into train, val, and test sets\n",
    "    train_count = int(len(df) * ratio[0] / sum(ratio))\n",
    "    val_count = int(len(df) * ratio[1] / sum(ratio))\n",
    "    test_count = len(df) - train_count - val_count\n",
    "\n",
    "    train_df = df.iloc[:train_count]\n",
    "    val_df = df.iloc[train_count:train_count + val_count]\n",
    "    test_df = df.iloc[train_count + val_count:]\n",
    "\n",
    "    # Create the output folders if they don't exist\n",
    "    os.makedirs(train_folder, exist_ok=True)\n",
    "    os.makedirs(val_folder, exist_ok=True)\n",
    "    os.makedirs(test_folder, exist_ok=True)\n",
    "\n",
    "    # Get the unique classes\n",
    "    unique_classes = df['Image'].unique()\n",
    "\n",
    "    # Create class subfolders in train, val, and test folders\n",
    "    for cls in unique_classes:\n",
    "        os.makedirs(os.path.join(train_folder, cls), exist_ok=True)\n",
    "        os.makedirs(os.path.join(val_folder, cls), exist_ok=True)\n",
    "        os.makedirs(os.path.join(test_folder, cls), exist_ok=True)\n",
    "\n",
    "    # Move the images to the corresponding class subfolders\n",
    "    for _, row in train_df.iterrows():\n",
    "        src = os.path.join(image_folder, f\"{row['ID']}.jpg\")\n",
    "        if is_image_valid(src):\n",
    "            shutil.move(src, os.path.join(train_folder, row['Image'], f\"{row['ID']}.jpg\"))\n",
    "        # shutil.move(os.path.join(image_folder, f\"{row['ID']}.jpg\"), os.path.join(train_folder, row['Image'], f\"{row['ID']}.jpg\"))\n",
    "    for _, row in val_df.iterrows():\n",
    "        src = os.path.join(image_folder, f\"{row['ID']}.jpg\")\n",
    "        if is_image_valid(src):\n",
    "            shutil.move(src, os.path.join(val_folder, row['Image'], f\"{row['ID']}.jpg\"))\n",
    "        # shutil.move(os.path.join(image_folder, f\"{row['ID']}.jpg\"), os.path.join(val_folder, row['Image'], f\"{row['ID']}.jpg\"))\n",
    "    for _, row in test_df.iterrows():\n",
    "        src = os.path.join(image_folder, f\"{row['ID']}.jpg\")\n",
    "        if is_image_valid(src):\n",
    "            shutil.move(src, os.path.join(test_folder, row['Image'], f\"{row['ID']}.jpg\"))\n",
    "        # shutil.move(os.path.join(image_folder, f\"{row['ID']}.jpg\"), os.path.join(test_folder, row['Image'], f\"{row['ID']}.jpg\"))\n",
    "\n",
    "split_balanced_images(image_folder, dataset_csv, train_folder, val_folder, test_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7c227cbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 13702 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True\n",
    ")\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    directory= './MVSA/train',\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7223390f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    7697\n",
       "1    5177\n",
       "0     828\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.Index(train_generator.classes).value_counts()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
