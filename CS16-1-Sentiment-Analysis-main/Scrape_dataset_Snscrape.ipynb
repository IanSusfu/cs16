{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e5b2c96f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting snscrape\n",
      "  Downloading snscrape-0.6.0.20230303-py3-none-any.whl (71 kB)\n",
      "Requirement already satisfied: lxml in c:\\users\\ian\\anaconda3\\lib\\site-packages (from snscrape) (4.7.1)\n",
      "Requirement already satisfied: pytz in c:\\users\\ian\\anaconda3\\lib\\site-packages (from snscrape) (2021.3)\n",
      "Requirement already satisfied: filelock in c:\\users\\ian\\anaconda3\\lib\\site-packages (from snscrape) (3.4.2)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\ian\\anaconda3\\lib\\site-packages (from snscrape) (4.10.0)\n",
      "Requirement already satisfied: requests[socks] in c:\\users\\ian\\anaconda3\\lib\\site-packages (from snscrape) (2.27.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\ian\\anaconda3\\lib\\site-packages (from beautifulsoup4->snscrape) (2.3.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\ian\\anaconda3\\lib\\site-packages (from requests[socks]->snscrape) (2020.6.20)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\ian\\anaconda3\\lib\\site-packages (from requests[socks]->snscrape) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\ian\\anaconda3\\lib\\site-packages (from requests[socks]->snscrape) (3.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\ian\\anaconda3\\lib\\site-packages (from requests[socks]->snscrape) (1.26.8)\n",
      "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in c:\\users\\ian\\anaconda3\\lib\\site-packages (from requests[socks]->snscrape) (1.7.1)\n",
      "Installing collected packages: snscrape\n",
      "Successfully installed snscrape-0.6.0.20230303\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "#pip install snscrape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4a5ab3fb",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          Date             User  \\\n",
      "0    2023-03-01 23:59:59+00:00      aguirreryan   \n",
      "1    2023-03-01 23:59:59+00:00        NPDigital   \n",
      "2    2023-03-01 23:59:59+00:00        Sirrah025   \n",
      "3    2023-03-01 23:59:59+00:00      _500dollars   \n",
      "4    2023-03-01 23:59:59+00:00      regji_spark   \n",
      "...                        ...              ...   \n",
      "4995 2023-03-01 23:58:27+00:00         swithp1h   \n",
      "4996 2023-03-01 23:58:27+00:00          _louixj   \n",
      "4997 2023-03-01 23:58:26+00:00        SethIliff   \n",
      "4998 2023-03-01 23:58:26+00:00  SureshK54739272   \n",
      "4999 2023-03-01 23:58:26+00:00      ScouseFlair   \n",
      "\n",
      "                                                  Tweet  \\\n",
      "0     @bexlewis361 It‚Äôs technically ‚ÄúGraupel‚Äù https:...   \n",
      "1     Women have always been a force for change.\\n\\n...   \n",
      "2     Hi, I am going live.\\nNew model here.\\nCan you...   \n",
      "3     @SlabsNRaw Done join thank you very much ‚ô•Ô∏èüöÄüöÄ ...   \n",
      "4     @offlinegremlin Please don't! https://t.co/JUK...   \n",
      "...                                                 ...   \n",
      "4995  THEY LITERALLY LOVE HER OMG üò≠üò≠üò≠ https://t.co/M...   \n",
      "4996    @Reversahh Omg I see me https://t.co/UeHfV6hXVA   \n",
      "4997  This is not a test BB.üëÄ‚òùüèªü´∂üèªü´µüèª https://t.co/PhK...   \n",
      "4998  #‡§∏‡§§‡§ó‡•Å‡§∞‡•Å_‡§∂‡•ã‡§≠‡§æ_‡§Ø‡§æ‡§§‡•ç‡§∞‡§æ\\nThe 13th Panth is being r...   \n",
      "4999  Alisson is in the Top 4 for most clean sheets ...   \n",
      "\n",
      "                                              Image_URL  \n",
      "0     [Photo(previewUrl='https://pbs.twimg.com/media...  \n",
      "1     [Photo(previewUrl='https://pbs.twimg.com/media...  \n",
      "2     [Photo(previewUrl='https://pbs.twimg.com/media...  \n",
      "3     [Photo(previewUrl='https://pbs.twimg.com/media...  \n",
      "4     [Gif(thumbnailUrl='https://pbs.twimg.com/tweet...  \n",
      "...                                                 ...  \n",
      "4995  [Photo(previewUrl='https://pbs.twimg.com/media...  \n",
      "4996  [Photo(previewUrl='https://pbs.twimg.com/media...  \n",
      "4997  [Video(thumbnailUrl='https://pbs.twimg.com/ext...  \n",
      "4998  [Photo(previewUrl='https://pbs.twimg.com/media...  \n",
      "4999  [Photo(previewUrl='https://pbs.twimg.com/media...  \n",
      "\n",
      "[5000 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "import snscrape.modules.twitter as sntwitter\n",
    "import pandas as pd\n",
    "\n",
    "query = \"lang:en until:2023-03-02 since:2023-03-01\"\n",
    "tweets = []\n",
    "limits = 5000\n",
    "\n",
    "for tweet in sntwitter.TwitterSearchScraper(query).get_items():\n",
    "    #print(vars(tweet))\n",
    "    #break\n",
    "    if len(tweets) == limits:\n",
    "        break\n",
    "    elif tweet.media != None:\n",
    "        tweets.append([tweet.date, tweet.user.username, tweet.rawContent, tweet.media])\n",
    "        \n",
    "df = pd.DataFrame(tweets, columns = ['Date', 'User', 'Tweet', 'Image_URL'])\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d852ac77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Photo(previewUrl='https://pbs.twimg.com/media/FqLEU_kakAMI1LX?format=jpg&name=small', fullUrl='https://pbs.twimg.com/media/FqLEU_kakAMI1LX?format=jpg&name=orig', altText=None)]\n"
     ]
    }
   ],
   "source": [
    "print(df['Image_URL'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "20c167d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.to_csv(\"tweetsk_in_english.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "750d7087",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"5000_eng_tweets_with_media_URL.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5e97f2c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
